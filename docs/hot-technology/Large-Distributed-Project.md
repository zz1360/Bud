# **大型分布式项目相关问题攻略**

#### 5.11.1   分布式事务

##### 5.12.1,1 分布式事务相关概念

1、什么是分布式系统？

部署在不同结点上的系统通过网络交互来完成协同工作的系统。

比如：充值加积分的业务，用户在充值系统向自己的账户充钱，在积分系统中自己积分相应的增加。充值系统和积分系统是两个不同的系统，一次充值加积分的业务就需要这两个系统协同工作来完成。

2、什么是事务？

事务是指由一组操作组成的一个工作单元，这个工作单元具有原子性（atomicity）、一致性（consistency）、隔离性（isolation）和持久性（durability）。

原子性：执行单元中的操作要么全部执行成功，要么全部失败。如果有一部分成功一部分失败那么成功的操作要全

部回滚到执行前的状态。 一致性：执行一次事务会使用数据从一个正确的状态转换到另一个正确的状态，执行前后

数据都是完整的。 隔离性：在该事务执行的过程中，任何数据的改变只存在于该事务之中，对外界没有影响，事务与事务之间是完全的隔离的。只有事务提交后其它事务才可以查询到最新的数据。 持久性：事务完成后对数据的改变会永久性的存储起来，即使发生断电宕机数据依然在。

3、什么是本地事务？

本地事务就是用关系数据库来控制事务，关系数据库通常都具有ACID特性，传统的单体应用通常会将数据全部存储在一个数据库中，会借助关系数据库来完成事务控制。

4、什么是分布式事务？

在分布式系统中一次操作由多个系统协同完成，这种一次事务操作涉及多个系统通过网络协同完成的过程称为分布式事务。这里强调的是多个系统通过网络协同完成一个事务的过程，并不强调多个系统访问了不同的数据库，即使多个系统访问的是同一个数据库也是分布式事务，如下图：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

另外一种分布式事务的表现是，一个应用程序使用了多个数据源连接了不同的数据库，当一次事务需要操作多个数据源，此时也属于分布式事务，当系统作了数据库拆分后会出现此种情况。

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif)

上面两种分布式事务表现形式以第一种据多

5、分布式事务有哪些场景？

1) 电商系统中的下单扣库存

电商系统中，订单系统和库存系统是两个系统，一次下单的操作由两个系统协同完成

2）金融系统中的银行卡充值

在金融系统中通过银行卡向平台充值需要通过银行系统和金融系统协同完成。

3）教育系统中下单选课业务

在线教育系统中，用户购买课程，下单支付成功后学生选课成功，此事务由订单系统和选课系统协同完成。

4） SNS系统的消息发送

在社交系统中发送站内消息同时发送手机短信，一次消息发送由站内消息系统和手机通信系统协同完成。

##### 5.12.1.2 CAP理论

如何进行分布式事务控制？CAP理论是分布式事务处理的理论基础，了解了CAP理论有助于我们研究分布式事务的

处理方案。

CAP理论是：分布式系统在设计时只能在一致性(Consistency)、可用性(Availability)、分区容忍性(Partition

Tolerance)中满足两种，无法兼顾三种。

通过下图理解CAP理论：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

一致性(Consistency)：服务A、B、C三个结点都存储了用户数据，三个结点的数据需要保持同一时刻数据一致性。

可用性(Availability)：服务A、B、C三个结点，其中一个结点宕机不影响整个集群对外提供服务，如果只有服务A结点，当服务A宕机整个系统将无法提供服务，增加服务B、C是为了保证系统的可用性。

分区容忍性(Partition Tolerance)：分区容忍性就是允许系统通过网络协同工作，分区容忍性要解决由于网络分区导致数据的不完整及无法访问等问题。

分布式系统不可避免的出现了多个系统通过网络协同工作的场景，结点之间难免会出现网络中断、网延延迟等现象，这种现象一旦出现就导致数据被分散在不同的结点上，这就是网络分区。

 

分布式系统能否兼顾C、A、P？

在保证分区容忍性的前提下一致性和可用性无法兼顾，如果要提高系统的可用性就要增加多个结点，如果要保证数

据的一致性就要实现每个结点的数据一致，结点越多可用性越好，但是数据一致性越差。

所以，在进行分布式系统设计时，同时满足“一致性”、“可用性”和“分区容忍性”三者是几乎不可能的。

 

CAP有哪些组合方式？

1、CA：放弃分区容忍性，加强一致性和可用性，关系数据库按照CA进行设计。

2、AP：放弃一致性，加强可用性和分区容忍性，追求最终一致性，很多NoSQL数据库按照AP进行设计。

说明：这里放弃一致性是指放弃强一致性，强一致性就是写入成功立刻要查询出最新数据。追求最终一致性是指允

许暂时的数据不一致，只要最终在用户接受的时间内数据 一致即可。

3、CP：放弃可用性，加强一致性和分区容忍性，一些强一致性要求的系统按CP进行设计，比如跨行转账，一次转

账请求要等待双方银行系统都完成整个事务才算完成。

说明：由于网络问题的存在CP系统可能会出现待等待超时，如果没有处理超时问题则整理系统会出现阻塞。

总结：

在分布式系统设计中AP的应用较多，即保证分区容忍性和可用性，牺牲数据的强一致性（写操作后立刻读取到最新数据），保证数据最终一致性。比如：订单退款，今日退款成功，明日账户到账，只要在预定的用户可以接受的时间内退款事务走完即可。

##### 5.12.1.3  解决方案

**一、两阶段提交协议（2PC）**

为解决分布式系统的数据一致性问题出现了两阶段提交协议（2 Phase Commitment Protocol），两阶段提交由协调者和参与者组成，共经过两个阶段和三个操作，部分关系数据库如Oracle、MySQL支持两阶段提交协议，本节讲解关系数据库两阶段提交协议。

参考：2PC：https://en.wikipedia.org/wiki/Two-phase_commit_protocol

2PC协议流程图：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)

1）第一阶段：准备阶段（prepare）

协调者通知参与者准备提交订单，参与者开始投票。

协调者完成准备工作向协调者回应Yes。

2）第二阶段：提交(commit)/回滚(rollback)阶段

协调者根据参与者的投票结果发起最终的提交指令。

如果有参与者没有准备好则发起回滚指令。

一个下单减库存的例子：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image010.gif)

1、应用程序连接两个数据源。

2、应用程序通过事务协调器向两个库发起prepare，两个数据库收到消息分别执行本地事务（记录日志），但不提交，如果执行成功则回复yes，否则回复no。

3、事务协调器收到回复，只要有一方回复no则分别向参与者发起回滚事务，参与者开始回滚事务。

4、事务协调器收到回复，全部回复yes，此时向参与者发起提交事务。如果参与者有一方提交事务失败则由事务协调器发起回滚事务。

2PC的优点：实现强一致性，部分关系数据库支持（Oracle、MySQL等）。

缺点：整个事务的执行需要由协调者在多个节点之间去协调，增加了事务的执行时间，性能低下。

解决方案有：springboot+Atomikos or Bitronix

3PC主要是解决协调者与参与者通信阻塞问题而产生的，它比2PC传递的消息还要多，性能不高。

详细参考3PC：https://en.wikipedia.org/wiki/Three-phase_commit_protocol

 

**二、事务补偿（TCC）**

TCC事务补偿是基于2PC实现的业务层事务控制方案，它是Try、Confirm和Cancel三个单词的首字母，含义如下：

1、Try 检查及预留业务资源

完成提交事务前的检查，并预留好资源。

2、Confirm 确定执行业务操作

对try阶段预留的资源正式执行。

3、Cancel 取消执行业务操作

对try阶段预留的资源释放。

下边用一个下单减库存的业务为例来说明：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif)

1、Try

下单业务由订单服务和库存服务协同完成，在try阶段订单服务和库存服务完成检查和预留资源。订单服务检查当前是否满足提交订单的条件（比如：当前存在未完成订单的不允许提交新订单）。库存服务检查当前是否有充足的库存，并锁定资源。

2、Confirm

订单服务和库存服务成功完成Try后开始正式执行资源操作。

订单服务向订单写一条订单信息。

库存服务减去库存。

3、Cancel

如果订单服务和库存服务有一方出现失败则全部取消操作。

订单服务需要删除新增的订单信息。

库存服务将减去的库存再还原。

优点：最终保证数据的一致性，在业务层实现事务控制，灵活性好。

缺点：开发成本高，每个事务操作每个参与者都需要实现try/confirm/cancel三个接口。

注意：TCC的try/confirm/cancel接口都要实现幂等性，在为在try、confirm、cancel失败后要不断重试。

**什么是幂等性？**

幂等性是指同一个操作无论请求多少次，其结果都相同。

幂等操作实现方式有：

1、操作之前在业务方法进行判断如果执行过了就不再执行。

2、缓存所有请求和处理的结果，已经处理的请求则直接返回结果。

1、 在数据库表中加一个状态字段（未处理，已处理），数据操作时判断未处理时再处理。

 

**三、消息队列实现最终一致**

本方案是将分布式事务拆分成多个本地事务来完成，并且由消息队列异步协调完成，如下图：

下边以下单减少库存为例来说明：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image014.gif)

1、订单服务和库存服务完成检查和预留资源。

2、订单服务在本地事务中完成添加订单表记录和添加“减少库存任务消息”。

3、由定时任务根据消息表的记录发送给MQ通知库存服务执行减库存操作。

4、库存服务执行减少库存，并且记录执行消息状态（为避免重复执行消息，在执行减库存之前查询是否执行过此消息）。

5、库存服务向MQ发送完成减少库存的消息。

6、订单服务接收到完成库存减少的消息后删除原来添加的“减少库存任务消息”。

实现最终事务一致要求：预留资源成功理论上要求正式执行成功，如果执行失败会进行重试，要求业务执行方法实现幂等。

优点 ：

由MQ按异步的方式协调完成事务，性能较高。

不用实现try/confirm/cancel接口，开发成本比TCC低。

缺点：

此方式基于关系数据库本地事务来实现，会出现频繁读写数据库记录，浪费数据库资源，另外对于高并发操作不是最佳方案。

 

**学成在线项目里，自动选课部分就是使用两个分布式服务（订单服务、学习服务）共同完成一件事即订单支付成功自动添加学生选课的需求**

#### 5.12.2 单点登陆

单点登录SSO（Single Sign On）说得简单点就是在一个多系统共存的环境下，用户在一处登录后，就不用在其他系统中登录，也就是用户的一次登录能得到其他所有系统的信任。单点登录在大型网站里使用得非常频繁，例如像阿里巴巴这样的网站，在网站的背后是成百上千的子系统，用户一次操作或交易可能涉及到几十个子系统的协作，如果每个子系统都需要用户认证，不仅用户会疯掉，各子系统也会为这种重复认证授权的逻辑搞疯掉。实现单点登录说到底就是要解决如何产生和存储那个信任，再就是其他系统如何验证这个信任的有效性，因此要点也就以下几个：

- 存储信任
- 验证信任

只要解决了以上的问题，达到了开头讲得效果就可以说是SSO。最简单实现SSO的方法就是用Cookie，实现流程如下所示：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image016.gif)

 

不难发现以上的方案是把信任存储在客户端的Cookie里，这种方法虽然实现方便但立马会让人质疑两个问题：

- Cookie不安全
- 不能跨域免登

对于第一个问题一般都是通过加密Cookie来处理，第二个问题是硬伤，其实这种方案的思路的就是要把这个信任关系存储在客户端，要实现这个也不一定只能用Cookie，用flash也能解决，flash的Shared Object API就提供了存储能力。

一般说来，大型系统会采取在服务端存储信任关系的做法，实现流程如下所示：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)

 

以上方案就是要把信任关系存储在单独的SSO系统（暂且这么称呼它）里，说起来只是简单地从客户端移到了服务端，但其中几个问题需要重点解决：

- 如何高效存储大量临时性的信任数据
- 如何防止信息传递过程被篡改
- 如何让SSO系统信任登录系统和免登系统

对于第一个问题，一般可以采用类似与redis的分布式缓存的方案，既能提供可扩展数据量的机制，也能提供高效访问。对于第二个问题，一般采取数字签名的方法，要么通过数字证书签名，要么通过像md5的方式，这就需要SSO系统返回免登URL的时候对需验证的参数进行md5加密，并带上token一起返回，最后需免登的系统进行验证信任关系的时候，需把这个token传给SSO系统，SSO系统通过对token的验证就可以辨别信息是否被改过。对于最后一个问题，可以通过白名单来处理，说简单点只有在白名单上的系统才能请求生产信任关系，同理只有在白名单上的系统才能被免登录。

#### 5.12.3 秒杀

秒杀要点总结：

1.架构：扩容，业务分离，数据分离

2.产品：下单按钮控制，秒杀答题削峰，简化页面设计

3.前端：限流（反作弊） 静态化

4.后端：内存队列

 

**秒杀一般会带来2 个问题：**

1、高并发

比较火热的秒杀在线人数都是10w 起的，如此之高的在线人数对于网站架构从前到后都是一种考验。

2、超卖

任何商品都会有数量上限，如何避免成功下订单买到商品的人数不超过商品数量的上限，这是每个抢购

活动都要面临的难题。

实际上超卖问题是高并发带来的一个子问题，但是因为这个问题太过致命，所以我们把他的解决方案单

独拿出来说。

 

**如何解决？**

1.架构层面：

秒杀架构设计原则：

尽量将请求拦截在系统上游

读多写少的常用多使用缓存

扩容，说白了加机器

系统隔离

为了避免短时间内的大访问量对现有网站业务造成的冲击，可以将秒杀系统独立部署。系统隔离更多是运

行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀还申请了单独的域名，目的也是让请求落到

不同的集群中。即使秒杀系统崩溃了，也不会对网站造成影响。

数据隔离

将即将被秒杀的热数据维护到redis。秒杀所调用的数据大部分都是热数据，比如会启用单独cache 集群或MySQL 数据库来放热点数据，目前也是不想0.01%的数据影响另外99.99%。

减库存操作

一种是拍下减库存另外一种是付款减库存；目前采用的“拍下减库存”的方式，拍下就是一瞬间的事，对用户体验会好些。

 

2.产品层面：

1).控制秒杀商品页面抢购按钮的可用/禁用。

购买按钮只有在秒杀开始的时候才能点亮，在此之前是灰色的，显示活动未开始。

2).增加了秒杀答题，基于时间分片削峰

秒杀答题一个很重要的目的是为了防止秒杀器。还有一个重要的功能，就是把峰值的下单请求给拉长了，从

以前的1s 之内延长到2~10s 左右，请求峰值基于时间分片了，这个时间的分片对服务端处理并发非常重要，

会减轻很大压力，另外由于请求的先后，靠后的请求自然也没有库存了，也根本到不了最后的下单步骤，所

以真正的并发写就非常有限了。其实这种设计思路目前也非常普遍，如支付宝的“咻一咻”已及微信的摇一摇。

3).秒杀页面设计简化：

秒杀场景业务需求与一般购物不同，用户更在意的是能够抢到商品而不是用户体验。所以秒杀商品页面应尽

可能简单并且拍下后地址等个人信息应该使用默认信息，减轻秒杀进行时系统负载，若有更改可以在秒杀结

束后进行更改。

 

3.前端层面

1)静态化以及页面缓存

将页面能够静态的部分都静态化，并将静态页面缓存于CDN，以及反向代理服务器，可能还要临时租借服务器。利用页面静态化、数据静态化，反向代理等方法可以避免带宽和sql 压力，但是随之而来一个问题，页面抢单按钮也不会刷新了，可以把js 文件单独放在js 服务器上，由另外一台服务器写定时任务来控制js 推送。另外还有一个问题，js 文件会被大部分浏览器缓存，我们可以使用xxx.js?v=随机数的方式来避免js 被缓存。

2)限流（反作弊）

a.针对同一个用户id 来实现，前端js 控制一个客户端几秒之内只能发送同一个请求，后端校验同一个uid

在几秒之内返回同一个页面

b.针对同一个ip 来实现，进行ip 检测，同一个ip 几秒之内不发送请求或者只返回同一个页面

c.针对多用户多ip 来实现，依靠数据分析

d.为了避免用户直接访问下单页面URL，需要将改URL 动态化，即使秒杀系统的开发者也无法在秒杀开始前

访问下单页面的URL。办法是在下单页面URL 加入由服务器端生成的随机数作为参数，在秒杀开始的时候才

能得到。

 

4.后端层面：

1).加入缓存redis：

因为秒杀是典型的读多写少的场景，适合操作内存而非操作硬盘；缓存工具redis 本身的操作是保证原子性的，所以可以保证请求了redis 的写的操作的线程安全性。

2).加入消息队列，利用队列进行削峰：

将用户请求放置于一个或多个队列中，队列中元素总和等于该商品库存总和，未进入队列的请求均失败。利用多线程轮询分别从一个或多个队列中取出用户请求。操作redis 进行减库存操作，成功减库存之后返回成功，并将用户信息与商品信息存入另一个队列当中，进行生成订单的操作。利用两个队列异步处理业务减轻秒杀高峰时期服务器负载。

3).程序计数器：

队列与缓存为了保证请求redis 的次数不超过总的库存量，利用一个程序计数器来这一点。程序计数器用JUC 包下原子类可以实现。

4).分布式锁

分布式情况下可以利用分布式锁来解决任务每次只能由一次服务来执行且不能重复执行。

分布式锁的实现：zk、redis

分布式锁的优化：先考虑是否可以去锁，然后考虑尽可能多用乐观锁，少用悲观锁。这里有一个问题，乐

观锁如果每一次都会有并发冲突的话性能反而不如悲观锁，那么难道真的多用乐观锁性能会比悲观锁高吗？选举考虑ha，比如心跳检测。

5).分布式去锁方案

利用集群并发加入队列，选举队列处理服务单点执行，这样可以保证并发实现和加锁一样的并发量但不会影响性能。

 

**补充：常见问题，搞活动秒杀抢购时库存是如何控制的？**

1、把商品的数量放到**redis**中。

2、秒杀时使用**decr命令**对商品数量减一。如果不是负数说明抢到。

3、一旦返回数值变为0说明商品已售完。

#### 5.12.4 集群和负载均衡

互联网飞速发展的今天,大用户量高并发已经成为互联网的主体.怎样能让一个网站能够承载几万个或几十万个用户的持续访问呢？这是一些中小网站急需解决的问题。用单机tomcat搭建的网站，在比较理想的状态下能够承受的并发访问量在150到200左右。按照并发访问量占总用户数量的5%到10%这样计算，单点tomcat网站的用户人数在1500到4000左右。对于一个为全国范围提供服务的网站显然是不够用的，为了解决这个问题引入了负载均衡方法。负载均衡就是一个web服务器解决不了的问题可以通过多个web服务器来平均分担压力来解决，并发过来的请求被平均分配到多个后台web服务器来处理，这样压力就被分解开来。

负载均衡服务器分为两种一种是通过硬件实现的负载均衡服务器，简称硬负载例如：f5。另一种是通过软件来实现的负载均衡，简称软负载:例如apache和nginx。硬负载和软负载相比前者作用的网络层次比较多可以作用到socket接口的数据链路层对发出的请求进行分组转发但是价格成本比较贵，而软负载作用的层次在http协议层之上可以对http请求进行分组转发并且因为是开源的所以几乎是0成本，并且阿里巴巴，京东等电商网站使用的都是Nginx服务器。

用nginx做反向代理服务器，经过配置**nginx.conf**配置反响代理，将请求转发给后端的tomcat集群，实现负载均衡。

##### 5.12.4.1 Nginx简介

Nginx是一款高性能的 http 服务器（c语言编写）。反向代理服务器及电子邮件（ IMAP/POP3 ）代理服务器。由俄罗斯的程序设计师 伊戈尔 · 西索夫 Igor Sysoev 所开发，官方测试 nginx 能够支支撑 5 万并发链接，并且 cpu 、内存等资源消耗却非常低，运行非常稳定。

 

**Nginx应用场景**：

1、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用 nginx 做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。

2、负载均衡。所谓的负载均衡简单说就是将一台服务原来承受的压力由多台服务器来分配，可以在nginx中实现tomcat集群，通过weight来分配权重。

3、 http 服务器(动静分离)。 Nginx 是一个 http 服务可以独立提供 http 服务。可以做网页静态服务器。

4、虚拟主 机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。

###### 反向代理

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image020.jpg)

用户A始终认为它访问的是原始服务器B而不是代理服务器Z，但实用际上反向代理服务器接受用户A的应答，从原始资源服务器B中取得用户A的需求资源，然后发送给用户A。由于防火墙的作用，只允许代理服务器Z访问原始资源服务器B。尽管在这个虚拟的环境下，防火墙和反向代理的共同作用保护了原始资源服务器B，但用户A并不知情。

这个功能只需在nginx的配置文件nginx.conf里面简单配置就行，配置如下：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image022.jpg)

proxy_pass: 127.0.0.1可以换成任何一个通的内网地址，这个ip表示你要真实访问的tomcat所在的位置，proxy_pass的值就表示你真正访问的域名是什么（站在公网服务器角度来说）。

###### 负载均衡

为了解决高并发问题，负载均衡服务器拦截所有的请求，采用负载均衡算法，分配到不同的tomcat上。简单说就是将一台服务原来承受的压力由多台服务器来分配，可以在nginx中实现tomcat集群，通过weight来分配权重。

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image024.jpg)

三种基本的负载均衡算法： **轮询、权重、ip绑定、基于开发语言。**

轮询： 这是nginx默认的负载均衡算法，简单来说就是从上到下按顺序轮流（127.0.0.1:8082轮完就轮到127.0.0.1:8081，127.0.0.1:8081轮完就轮到127.0.0.1:8082）。注意：mzd的地方需要保持一致。

权重： 我的理解就是哪台服务器配置好就多轮几次，或者你就想某个服务器多轮几次。简单来说就是轮到次数的比例，数字越大表示轮到的概率越大。（个人认为weight都设置为1的时候和轮询没什么区别）

ip绑定： 我的理解就是你第一次访问的时候，nginx会根据你的ip通过哈希算法，算出某个值，然后取分配哪个tomcat，当你第二次访问，第三次访问。。。之后的任何一次访问都是去请求那个第一次访问的tomcat。

基于开发语言：这种分发方式适用于混合开发的网站，某些大型网站既有php也有jsp，就可以基于开发语言分发。

###### 动静分离

静态资源： html、js、css、图片、音乐、视频等。

动态资源： 我的理解就是我们所说的接口。这里需要注意的是：themleaf、freemark这些模板引擎的html不是静态资源而应该属于动态资源（个人认为）。

实现动静分离的两种方法： 通过不同域名来拦截和location来拦截。

做法：所有动态资源的请求交给Tomcat，而静态资源的请求（例如图片、视频、CSS、JavaScript文件等）则直接由Nginx返回到浏览器，这样能大大减轻Tomcat的压力。

配置如下：

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image026.jpg)

#### 5.12.5 [MyCAT实现MySQL的读写分离](http://www.cnblogs.com/ivictor/p/5131480.html)

在MySQL中间件出现之前，对于MySQL主从集群，如果要实现其读写分离，一般是在程序端实现，这样就带来一个问题，即数据库和程序的耦合度太高，如果我数据库的地址发生改变了，那么我程序端也要进行相应的修改，如果数据库不小心挂掉了，则同时也意味着程序的不可用，而这对很多应用来说，并不能接受。

引入MySQL中间件能很好的对程序端和数据库进行解耦，这样，程序端只需关注数据库中间件的地址，而无需知晓底层数据库是如何提供服务。

作为当前炙手可热的**MySQL中间件**，MyCAT实现MySQL主从集群的读写分离自是应有之义，其配置也相当简单。

 

**为什么需要MyCat？**

虽然云计算时代，传统数据库存在着先天性的弊端，但是NoSQL数据库又无法将其替代。如果传统数据易于扩展，可切分，就可以避免单机（单库）的性能缺陷。

MyCat的目标就是：低成本地将现有的单机数据库和应用平滑迁移到“云”端，解决数据存储和业务规模迅速增长情况下的数据瓶颈问题。2014年MyCat首次在上海的《中华架构师》大会上对外宣讲引发围观，更多的人参与进来，随后越来越多的项目采用了MyCat。

MyCat截至到2015年4月，保守估计已经有超过60个项目在使用，主要应用在电信领域、互联网项目，大部分是交易和管理系统，少量是信息系统。比较大的系统中，数据规模单表单月30亿。

 

**MyCat是什么？**

从定义和分类来看，它是一个开源的分布式数据库系统，是一个实现了MySQL协议的服务器，前端用户可以把它看作是一个数据库代理，用MySQL客户端工具和命令行访问，而其后端可以用MySQL原生协议与多个MySQL服务器通信，也可以用JDBC协议与大多数主流数据库服务器通信，其核心功能是分表分库，即将一个大表水平分割为N个小表，存储在后端MySQL服务器里或者其他数据库里。

MyCat发展到目前的版本，已经不是一个单纯的MySQL代理了，它的后端可以支持MySQL、SQL Server、Oracle、DB2、PostgreSQL等主流数据库，也支持MongoDB这种新型NoSQL方式的存储，未来还会支持更多类型的存储。而在最终用户看来，无论是那种存储方式，在MyCat里，都是一个传统的数据库表，支持标准的SQL语句进行数据的操作，这样一来，对前端业务系统来说，可以大幅降低开发难度，提升开发速度

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image028.gif)

图1 MyCat架构设计图

 

MyCat技术原理：

MyCat 技术原理中最重要的一个动词是“拦截”，它拦截了用户发送过来的SQL 语句，首先对SQL 语句做了一

些特定的分析：如分片分析、路由分析、读写分离分析、缓存分析等，然后将此SQL 发往后端的真实数据库，

并将返回的结果做适当的处理，最终再返回给用户。

![img](file:///C:/Users/79287/AppData/Local/Temp/msohtmlclip1/01/clip_image030.gif)

 

如图所示，Orders表被分为三个分片datanode（简称dn)，这三个分片是分布在两台MySQL Server上(DataHost)，即datanode=database@datahost方式，因此你可以用一台到N台服务器来分片，分片规则为（sharding rule)典型的字符串枚举分片规则，一个规则的定义是分片字段（sharding column)+分片函数(rule function)，这里的分片字段为prov而分片函数为字符串枚举方式。当MyCat收到一个SQL时，会先解析这个SQL，查找涉及到的表，然后看此表的定义，如果有分片规则，则获取到SQL里分片字段的值，并匹配分片函数，得到该SQL对应的分片列表，然后将SQL发往这些分片去执行，最后收集和处理所有分片返回的结果数据，并输出到客户端。以select * from Orders where prov=?语句为例，查到prov=wuhan，按照分片函数，wuhan返回dn1，于是SQL就发给了MySQL1，去取DB1上的查询结果，并返回给用户。如果上述SQL改为select * from Orders where prov in (‘wuhan’,‘beijing’)，那么，SQL就会发给MySQL1与MySQL2去执行，然后结果集合并后输出给用户。但通常业务中我们的SQL会有Order By以及Limit翻页语法，此时就涉及到结果集在MyCat端的二次处理，这部分的代码也比较复杂，而最复杂的则属两个表的Jion问题，为此，MyCat提出了创新性的ER分片、全局表、HBT（Human Brain Tech)人工智能的Catlet等。